{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importing CV\r\n",
    "import cv2 as cv \r\n",
    "import numpy as np\r\n",
    "# Read images\r\n",
    "img = cv.imread('mango.jpeg')\r\n",
    "cv.imshow('Image', img)\r\n",
    "cv.waitKey(0) # cv.waitKey(0) --> displays image as long as we want.\r\n",
    "img.shape ##height, width, channel"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(325, 474, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read and process videos:\r\n",
    "# 1) Capture video\r\n",
    "# 2) Read images frame by frame.\r\n",
    "# 3) display images as video\r\n",
    "vid = cv.VideoCapture('onboarding.spec.js.mp4')\r\n",
    "while True:\r\n",
    "    success, image = vid.read()\r\n",
    "    if success:\r\n",
    "        image = cv.resize(image, (640, 480))\r\n",
    "        cv.imshow('vid', image)\r\n",
    "        cv.waitKey(1)\r\n",
    "        if cv.waitKey(1) == ord('q'):\r\n",
    "            break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Read Web cam\r\n",
    "width = 640\r\n",
    "height = 480\r\n",
    "vid = cv.VideoCapture(0)\r\n",
    "vid.set(3, width)\r\n",
    "vid.set(4, height)\r\n",
    "\r\n",
    "while True:\r\n",
    "    success, image = vid.read()\r\n",
    "    if success:\r\n",
    "        cv.imshow('Video', image)\r\n",
    "        if cv.waitKey(71) == ord('q'):\r\n",
    "            break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Resize, Crop an image\r\n",
    "import cv2 as cv\r\n",
    "img = cv.imread('mango.jpeg')\r\n",
    "scale = 0.8\r\n",
    "height, width = int(img.shape[0]*scale), int(img.shape[1]*scale)\r\n",
    "img_cropped = cv.resize(img, (height, width))\r\n",
    "cv.imshow('Original', img)\r\n",
    "cv.imshow('resizedCropped', img[100:500, 300:600])\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### Convert from BGR to Gray Scale\r\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\r\n",
    "cv.imshow('Gray', img_gray)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "### Image translation and rotation\r\n",
    "# 1) create a translation matrix\r\n",
    "# 2) Affine transformationw\r\n",
    "import numpy as np\r\n",
    "x, y = 100, -50\r\n",
    "translation_matrix = np.float32([[1, 0, x], [0, 1, y]]) # [[1, 0, magnitude], [0, 1, direction]]\r\n",
    "img_translated = cv.warpAffine(img, translation_matrix, (img.shape[1], img.shape[0])) # (width, height)\r\n",
    "cv.imshow('Translated', img_translated)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Rotation\r\n",
    "# 1) Get center (point of rotation)\r\n",
    "# 2) Define Rotation Matrix --> getRotationMatrix2D()\r\n",
    "pointRot = img.shape[1]//2, img.shape[0]//2\r\n",
    "angle = 45\r\n",
    "scale = 0.5\r\n",
    "rotationMatrix = cv.getRotationMatrix2D(pointRot, angle, scale)\r\n",
    "rotated = cv.warpAffine(img, rotationMatrix, (img.shape[1], img.shape[0]))\r\n",
    "cv.imshow('Rotated', rotated)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Bluring Images\r\n",
    "# 1) Initialize kernal size\r\n",
    "# 2) Initialize sigmaX --> Kernel's standard deviation in x direction\r\n",
    "k_size = (7, 7) # should be in odd numbers, higher number --> blurrier\r\n",
    "sigmaX = 0\r\n",
    "blurredImg = cv.GaussianBlur(img, k_size, sigmaX=sigmaX)\r\n",
    "cv.imshow('Blurred', blurredImg)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Wrapping an Image\r\n",
    "# 1) Get points ---> use paint to get 4 corners of area to be extracted\r\n",
    "# 2) Create Perspective Matrix \r\n",
    "# 3) Wrape Image\r\n",
    "width, height = 400, 100\r\n",
    "ptsA = np.float32([[2, 226], [239, 196], [59, 304], [270, 262]])\r\n",
    "ptsB = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\r\n",
    "matrix = cv.getPerspectiveTransform(ptsA, ptsB)\r\n",
    "print(matrix)\r\n",
    "extracted_img = cv.warpPerspective(img, matrix, (width, height))\r\n",
    "cv.imshow('Extracted', extracted_img)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 1.14045743e+00 -8.33411201e-01  1.86070017e+02]\n",
      " [ 1.24746465e-01  9.85497073e-01 -2.22971831e+02]\n",
      " [-7.88622067e-04 -3.73941107e-04  1.00000000e+00]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Add Shapes\r\n",
    "# 1) Draw a circle: cv2.circle() -> 5 parameters: img, center, radius, color, circleThickness\r\n",
    "img = cv.imread('mango.jpeg')\r\n",
    "center = (321, 159)\r\n",
    "raduis = 140\r\n",
    "color = (0, 0, 255)\r\n",
    "circleThickness = 5\r\n",
    "img_circled = img.copy()\r\n",
    "cv.circle(img_circled, center, raduis, color, circleThickness)\r\n",
    "cv.imshow('Image with circle', img_circled)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# 2) Draw a rectangle: cv2.rectangle() -> 5 parameters: img, leftTopCorner, rightBottomCorner, color, rectangleThickness\r\n",
    "leftTopCorner = (208, 20)\r\n",
    "rightBottomCorner = (457, 280)\r\n",
    "color = (0, 255, 0)\r\n",
    "rectangleThickness = 5\r\n",
    "img_rec = img.copy()\r\n",
    "cv.rectangle(img_rec, leftTopCorner, rightBottomCorner, color, rectangleThickness)\r\n",
    "cv.imshow('Image with rectangle', img_rec)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# 3) Draw a line: cv2.line() -> 5 parameters: img, startPoint, endPoint, color, lineThickness\r\n",
    "startPoint = (0, 0)\r\n",
    "endPoint = (474, 325)\r\n",
    "color = (0, 255, 0)\r\n",
    "lineThickness = 5\r\n",
    "img_line = img.copy()\r\n",
    "cv.line(img_line, startPoint, endPoint, color, lineThickness)\r\n",
    "cv.imshow('Image with line', img_line)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Add Text: render image, add text, dispaly it\r\n",
    "img = cv.imread('mango.jpeg')\r\n",
    "text = 'Mango'\r\n",
    "startPt = (19, 38)\r\n",
    "color = (0, 0, 255) # red --> BGR\r\n",
    "fontSz = 1 # 15 px\r\n",
    "fontType = cv.FONT_HERSHEY_COMPLEX\r\n",
    "thickness = 1\r\n",
    "img_text = cv.putText(img, text, startPt, fontType, fontSz, color, thickness)\r\n",
    "cv.imshow('With Text', img_text)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Split and Merge color Channels: Read image, Split color channels, Merge colors, Display image.\r\n",
    "b, g, r = cv.split(img)\r\n",
    "cv.imshow('R', r)\r\n",
    "cv.imshow('G', g)\r\n",
    "cv.imshow('B', b)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Merge\r\n",
    "merged = cv.merge([b, g, r])\r\n",
    "cv.imshow('Merged', merged)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Joining images horizontally and vertically --> images should be the same size.\r\n",
    "# horizontally\r\n",
    "imgHor = np.hstack((b, g))\r\n",
    "cv.imshow('Stacked horizontally', imgHor)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# vertically\r\n",
    "imgVer = np.vstack((b, g))\r\n",
    "cv.imshow('Stacked vertically', imgVer)\r\n",
    "cv.waitKey(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.11.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.11.3 64-bit"
  },
  "interpreter": {
   "hash": "ac5dd863468244619c7fced7518372bf3cd36c113782136ac6ec3e547102faee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}